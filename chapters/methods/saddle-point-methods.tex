\section{First Order Saddle Point Methods}
\label{sec:sps}

Finding saddle points is a non-trivial task in multiple dimensions, when only local information is available and computational resources are limited, such that calculation of the Hessian matrix is infeasible.

\incomplete

% ------------------------------------------------------------------
\subsection{Nudged Elastic Band}
\label{sec:neb}

Finding Steepest Decent Paths (SDPs) from a given point is simple by following the gradient with a small step size.
On the other hand, finding specific SDPs that end at minima is not.
The goal here is to find two SDPs each leading from the same \sap1 to different minima without any further information than the minima.


\incomplete

% ------------------------------------------------------------------
\subsection{Dimer}
\label{sec:dimer}

The Dimer algorithm~\cite{dimer-original-1999} is in essence a method for finding the eigenmode corresponding to the lowest eigenvalue of the Hessian, while performing no direct calculations of the second derivatives.
This information is then used to locate \sap1s.

%The Dimer method was inspired by Voter\cite{voter-hyperdynamics-1997}

Given only an initial point, $\vR$, on a multidimensional function, $V(\vR)$, the goal is to, iteratively, locate a nearby \sap1, using no direct calculation of the Hessian, i.e. using only the function's values and its gradient, $\nabla V(\vR)$.
Indirect information about the Hessian is, however, used in the form of an estimate of the eigenmode corresponding to its lowest eigenvalue (the minimum mode).
Using the minimum mode, $\uvn$, it is possible to locally transform \sap1s to minima while using conventional techniques to move up-hill and locate the \sap1.

The dimer method can be split into three independent phases.
\ben{dimer-phases}
\item Estimating the minimum mode.
\item Transforming the gradient to make \sap1 seem as minima.
\item Translating the point according to the transformed gradient.
\een
Only the first of the phases is unique to the dimer algorithm.
A setup phase is also required if the search starts from a minimum.???
\recent

\subsubsection{Minimum Mode Estimation}
Estimating the second derivative of $V$ along a given unit vector, $\uvs$, at point $\vR$ can be done numerically, using finite differences.
For the occasion, a pair of points (the dimer), $[\vR_\text{A}, \vR_\text{B}]$, are chosen, close to current point $\vR_0$, such that
\beq{dimer-separation}
\vR_\text{A} = \vR_0 + \Dsep \uvs \quad \text{and} \quad \vR_\text{B} = \vR_0  - \Dsep \uvs,
\eeq
where $\Dsep$ is a predefined constant to determine the length of the dimer and the separation in the finite difference estimate.
Using only the function's values, the second derivative (or curvature), $C_\vs$, becomes
\beq{second-derivative-function}
C_\vs \equiv \frac{\partial^2 V}{\partial \uvs^2} \approx \frac{V_\text{A} + V_\text{B} - 2V_0}{\Dsep^2},
\eeq
where $V_\text{x} \equiv V(\vR_\text{x})$.
As the gradient points away from each minimum, it is convenient to define a force, $\vF$ that points towards minima instead, for use in the iterative minima search,
\beq{gradient-force}
\vF_\text{x} \equiv - \nabla V(\vR_\text{x}).
\eeq
Should the gradient is readily available, as it often is, \fref{eq:second-derivative-function} can be rewritten to depend on it instead,
\beq{second-derviative-gradient}
C_\vs \approx \frac{(\vF_\text{B} - \vF_\text{A}) \cdot \uvs}{\Dsep}.
\eeq
Rotating $\uvs$ around $\vR_0$, according to the rotational force,
\beq{rotational-force}
%\vF^\circlearrowright = (\vF_\text{A} - (\vF_\text{A} \cdot \uvs)\uvs) - (\vF_\text{B} - (\vF_\text{B} \cdot \uvs)\uvs)
\vF^\circlearrowright = \vF_\text{A} - \vF_\text{B} + ((\vF_\text{B} - \vF_\text{A}) \cdot \uvs)\uvs,
\eeq
until $C_\vs$ is minimized yields an estimate for, both, the lowest eigenvalue, $C_\text{min} = C_\vs$, of the Hessian and its corresponding eigenmode, the minimum mode, $\uvn$.
A number of rotational schemes can be employed, such as \missing

Often $\vF_0$ needs to be calculated to get a more accurate translational force (see below), this can be taken advantage of in order to cut down the amount of computations.
The gradient at either of the dimer's endpoints can be extrapolated from the other two~\cite{dimer-olsen-2004},
\beq{dimer-point-extrapolate}
\vF_\text{B} = 2\vF_0 - \vF_\text{A},
\eeq
with $\vF_\text{B}$ being the extrapolated, virtual, force.
Since $\vF_0$ is static, performing this extrapolation yields significant reductions in \missing up to a facgtor of $1/2 - 1$...

Further extrapolations are possible ... if multiple rotations are required (which is often not the case) \missing

\recent

\incomplete

\subsubsection{Gradient Transformation}
Once a minimum mode estimate is available for the current point, $\vR_0$, it is possible to transform the force so that any \sap1 is transformed to a minimum.
As discussed above, \sap1s are stationary (with zero gradient) and the Hessian has one and only one negative eigenvalue.
%As discussed above, saddle points are stationary and the Hessian has as many negative eigenvalues as the order of the saddle point, i.c. for a \sap1 the Hessian has one and only one negative eigenvalue.
The goal is thus to maximize the function's value along the minimum mode while minimizing it along all other eigenmodes.
This can be achieved, simply, by inverting any force components along the minimum mode,
\beq{dimer-transform}
\vF_0^\text{t} = \vF_0 - (\vF_0 \cdot \uvn)\uvn.
\eeq

A different force transformation,
\beq{dimer-transform-minima}
\vF_0^\text{t} = -\vF_0,
\eeq
is often used in areas of positive curvature in order to decrease the amount of iterations spent near minima.
This latter transformation simply inverts the whole force.

\recent

\subsubsection{Iterative Translation}
After the force has been transformed such that \sap1s appear as minima - \sap1s, however, remain unchanged with regards to the function's value - it is possible to use conventional algorithms for finding minima as long as they support a systematic increase in the function's value.
\tblue{Should this be detailed any further?}

\recent

